# å¸å®‰å¹¿åœº KOL æ–‡ç« çˆ¬è™«

ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„å¸å®‰å¹¿åœºï¼ˆBinance Squareï¼‰KOL æ–‡ç« çˆ¬è™«å·¥å…·ï¼Œæ”¯æŒæ™ºèƒ½å»é‡ã€å®šæ—¶è°ƒåº¦å’Œæ•°æ®åº“å­˜å‚¨ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- **æ™ºèƒ½å»é‡çˆ¬å–**ï¼šè¾¹çˆ¬è¾¹æ£€æŸ¥æ•°æ®åº“ï¼Œé‡åˆ°é‡å¤æ–‡ç« è‡ªåŠ¨åœæ­¢ï¼Œé¿å…é‡å¤æŠ“å–
- **å®šæ—¶è‡ªåŠ¨è¿è¡Œ**ï¼šæ”¯æŒå®šæ—¶è°ƒåº¦å™¨ï¼Œè‡ªåŠ¨å®šæœŸçˆ¬å–æœ€æ–°æ–‡ç« 
- **æ•°æ®åº“æŒä¹…åŒ–**ï¼šSQLite æ•°æ®åº“å­˜å‚¨ï¼Œæ”¯æŒå»é‡ã€æŸ¥è¯¢ã€ç»Ÿè®¡
- **æµè§ˆå™¨è‡ªåŠ¨åŒ–**ï¼šåŸºäº DrissionPageï¼Œæœ‰æ•ˆç»•è¿‡ Cloudflare ç­‰åçˆ¬è™«æœºåˆ¶
- **è¯¦ç»†æ—¥å¿—è®°å½•**ï¼šå®Œæ•´çš„æ—¥å¿—ç³»ç»Ÿï¼Œæ–¹ä¾¿è°ƒè¯•å’Œç›‘æ§

## ğŸ“ é¡¹ç›®ç»“æ„

```
binance_square_scraper/
â”œâ”€â”€ scrapers/                   # çˆ¬è™«æ¨¡å—
â”‚   â”œâ”€â”€ base.py                # åŸºç¡€çˆ¬è™«ç±»
â”‚   â””â”€â”€ binance_square.py      # å¸å®‰å¹¿åœºçˆ¬è™«å®ç°
â”œâ”€â”€ utils/                      # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ logger.py              # æ—¥å¿—å·¥å…·
â”‚   â”œâ”€â”€ database.py            # æ•°æ®åº“æ“ä½œæ¨¡å—
â”‚   â””â”€â”€ scheduler.py           # å®šæ—¶è°ƒåº¦å™¨
â”œâ”€â”€ database/                   # æ•°æ®åº“æ–‡ä»¶ç›®å½•
â”‚   â””â”€â”€ binance_square.db      # SQLiteæ•°æ®åº“ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”œâ”€â”€ logs/                       # æ—¥å¿—æ–‡ä»¶ç›®å½•
â”œâ”€â”€ drission_research.py        # è°ƒç ”è„šæœ¬
â”œâ”€â”€ main.py                     # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ run_scheduler.py            # å®šæ—¶è°ƒåº¦å™¨å¯åŠ¨è„šæœ¬
â”œâ”€â”€ config.json                 # é…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt            # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ pyproject.toml              # é¡¹ç›®é…ç½®ï¼ˆuvï¼‰
â””â”€â”€ README.md                   # é¡¹ç›®æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# ä½¿ç”¨ pip
pip install -r requirements.txt

# æˆ–ä½¿ç”¨ uvï¼ˆæ¨èï¼Œæ›´å¿«ï¼‰
uv pip install -r requirements.txt
```

### 2. é…ç½®é¡¹ç›®

ç¼–è¾‘ `config.json` æ–‡ä»¶ï¼š

```json
{
  "kol_username": "goingsun",           // ç›®æ ‡ KOL ç”¨æˆ·å
  "database": {
    "db_path": "database/binance_square.db"
  },
  "scheduler_config": {
    "enabled": true,                     // æ˜¯å¦å¯ç”¨å®šæ—¶ä»»åŠ¡
    "interval_hours": 1,                 // è¿è¡Œé—´éš”ï¼ˆå°æ—¶ï¼‰
    "interval_minutes": 0,               // è¿è¡Œé—´éš”ï¼ˆåˆ†é’Ÿï¼‰
    "headless": true,                    // æ˜¯å¦æ— å¤´æ¨¡å¼
    "run_immediately": false             // å¯åŠ¨æ—¶æ˜¯å¦ç«‹å³æ‰§è¡Œ
  }
}
```

### 3. è¿è¡Œæ–¹å¼

#### æ–¹å¼ä¸€ï¼šå•æ¬¡æ‰‹åŠ¨è¿è¡Œ

```python
from scrapers import BinanceSquareScraper

# åˆ›å»ºçˆ¬è™«å®ä¾‹
scraper = BinanceSquareScraper(
    kol_username="goingsun",
    headless=False,           # æ˜¾ç¤ºæµè§ˆå™¨
    save_to_db=True           # ä¿å­˜åˆ°æ•°æ®åº“
)

# æ‰§è¡Œçˆ¬å–
with scraper:
    new_articles = scraper.scrape()
    print(f"æœ¬æ¬¡è·å– {len(new_articles)} ç¯‡æ–°æ–‡ç« ")
```

#### æ–¹å¼äºŒï¼šå¯åŠ¨å®šæ—¶è°ƒåº¦å™¨

```bash
# å¯åŠ¨å®šæ—¶è°ƒåº¦å™¨
python run_scheduler.py

# æˆ–ä½¿ç”¨ uv
uv run run_scheduler.py
```

è°ƒåº¦å™¨ä¼šæŒ‰ç…§é…ç½®çš„æ—¶é—´é—´éš”è‡ªåŠ¨è¿è¡Œçˆ¬è™«ä»»åŠ¡ã€‚

## â° å®šæ—¶è°ƒåº¦å™¨

### é…ç½®å®šæ—¶ä»»åŠ¡

åœ¨ `config.json` ä¸­é…ç½®è°ƒåº¦å™¨ï¼š

```json
{
  "scheduler_config": {
    "enabled": true,              // æ˜¯å¦å¯ç”¨å®šæ—¶ä»»åŠ¡
    "interval_hours": 1,          // é—´éš”å°æ—¶æ•°
    "interval_minutes": 0,        // é—´éš”åˆ†é’Ÿæ•°
    "headless": true,             // æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼ï¼ˆæ¨èï¼‰
    "run_immediately": false      // å¯åŠ¨æ—¶æ˜¯å¦ç«‹å³æ‰§è¡Œä¸€æ¬¡
  }
}
```

### è¿è¡Œè°ƒåº¦å™¨

```bash
# å¯åŠ¨å®šæ—¶è°ƒåº¦å™¨
python run_scheduler.py
```

è°ƒåº¦å™¨å¯åŠ¨åä¼šæ˜¾ç¤ºï¼š
- å·²æ³¨å†Œçš„ä»»åŠ¡åˆ—è¡¨
- è§¦å‘å™¨é…ç½®ä¿¡æ¯
- ä¸‹æ¬¡è¿è¡Œæ—¶é—´
- å®æ—¶æ‰§è¡Œæ—¥å¿—

### æ—¥å¿—æ–‡ä»¶

- `logs/scheduler.log` - è°ƒåº¦å™¨æ—¥å¿—
- `logs/binance_square_scraper.log` - çˆ¬è™«æ‰§è¡Œæ—¥å¿—
- `logs/database.log` - æ•°æ®åº“æ“ä½œæ—¥å¿—

### åœæ­¢è°ƒåº¦å™¨

åœ¨è¿è¡Œçš„ç»ˆç«¯ä¸­æŒ‰ `Ctrl+C` å³å¯åœæ­¢è°ƒåº¦å™¨ã€‚

### éƒ¨ç½²å»ºè®®

#### Windows éƒ¨ç½²

**æ–¹æ¡ˆ 1ï¼šä½¿ç”¨ Windows ä»»åŠ¡è®¡åˆ’ç¨‹åº**

1. åˆ›å»ºæ‰¹å¤„ç†æ–‡ä»¶ `start_scheduler.bat`ï¼š
```batch
@echo off
cd /d "C:\path\to\project"
python run_scheduler.py
```

2. åœ¨ä»»åŠ¡è®¡åˆ’ç¨‹åºä¸­åˆ›å»ºä»»åŠ¡ï¼š
   - è§¦å‘å™¨ï¼šç³»ç»Ÿå¯åŠ¨æ—¶
   - æ“ä½œï¼šè¿è¡Œ `start_scheduler.bat`

**æ–¹æ¡ˆ 2ï¼šä½¿ç”¨ NSSM (Non-Sucking Service Manager)**

```bash
nssm install BinanceScraper "C:\Python\python.exe" "C:\path\to\project\run_scheduler.py"
nssm start BinanceScraper
```

#### Linux éƒ¨ç½²

**ä½¿ç”¨ systemd æœåŠ¡**

åˆ›å»ºæœåŠ¡æ–‡ä»¶ `/etc/systemd/system/binance-scraper.service`ï¼š

```ini
[Unit]
Description=Binance Square Scheduler
After=network.target

[Service]
Type=simple
User=your_user
WorkingDirectory=/path/to/project
ExecStart=/usr/bin/python3 /path/to/project/run_scheduler.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

å¯åŠ¨æœåŠ¡ï¼š
```bash
sudo systemctl daemon-reload
sudo systemctl enable binance-scraper
sudo systemctl start binance-scraper
sudo systemctl status binance-scraper
```

## ğŸ’¾ æ•°æ®åº“å­˜å‚¨

é¡¹ç›®ä½¿ç”¨ SQLite æ•°æ®åº“æŒä¹…åŒ–å­˜å‚¨çˆ¬å–çš„æ–‡ç« æ•°æ®ã€‚

### æ™ºèƒ½å»é‡æœºåˆ¶

çˆ¬è™«é‡‡ç”¨**æ™ºèƒ½å»é‡æ¨¡å¼**ï¼Œè¾¹æå–è¾¹æ£€æŸ¥æ•°æ®åº“ï¼Œè‡ªåŠ¨åœæ­¢é‡å¤æŠ“å–ï¼š

**å·¥ä½œæµç¨‹ï¼š**
1. è®¿é—® KOL ä¸»é¡µå¹¶æå–å½“å‰é¡µé¢çš„æ‰€æœ‰æ–‡ç« 
2. é€ç¯‡æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²å­˜åœ¨äºæ•°æ®åº“ï¼ˆé€šè¿‡å†…å®¹å“ˆå¸Œï¼‰
3. å¦‚æœæ˜¯æ–°æ–‡ç« ï¼Œç«‹å³ä¿å­˜åˆ°æ•°æ®åº“
4. å¦‚æœæ˜¯é‡å¤æ–‡ç« ï¼Œå¢åŠ é‡å¤è®¡æ•°
5. è¿ç»­é‡åˆ° 2 ç¯‡é‡å¤æ–‡ç« æ—¶ï¼Œè‡ªåŠ¨åœæ­¢çˆ¬å–
6. è‡ªåŠ¨è·³è¿‡ç½®é¡¶æ–‡ç« 

**æ ¸å¿ƒç‰¹æ€§ï¼š**
- âœ“ è‡ªåŠ¨å»é‡ï¼ˆåŸºäº SHA256 å†…å®¹å“ˆå¸Œï¼‰
- âœ“ æ™ºèƒ½åœæ­¢ï¼ˆé‡åˆ°é‡å¤æ–‡ç« è‡ªåŠ¨ç»“æŸï¼‰
- âœ“ è·³è¿‡ç½®é¡¶æ–‡ç« 
- âœ“ å®æ—¶æ˜¾ç¤ºçˆ¬å–è¿›åº¦
- âœ“ è¯¦ç»†çš„æ—¥å¿—è®°å½•

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from scrapers import BinanceSquareScraper

# åˆ›å»ºçˆ¬è™«å®ä¾‹
scraper = BinanceSquareScraper(
    kol_username="goingsun",
    headless=False,
    save_to_db=True,
    db_path="database/binance_square.db"
)

# æ‰§è¡Œçˆ¬å–
with scraper:
    new_articles = scraper.scrape()
    print(f"æœ¬æ¬¡è·å– {len(new_articles)} ç¯‡æ–°æ–‡ç« ")
```

### æ•°æ®åº“è¡¨ç»“æ„

```sql
CREATE TABLE articles (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    content_hash TEXT UNIQUE NOT NULL,      -- æ–‡ç« å”¯ä¸€å“ˆå¸Œå€¼ï¼ˆSHA256ï¼‰
    author TEXT NOT NULL,                    -- ä½œè€…ç”¨æˆ·å
    card_title TEXT,                         -- æ–‡ç« æ ‡é¢˜
    card_description TEXT NOT NULL,          -- æ–‡ç« å†…å®¹
    create_time TEXT,                        -- å‘å¸ƒæ—¶é—´
    imgs TEXT,                               -- å›¾ç‰‡åˆ—è¡¨ï¼ˆJSON æ ¼å¼ï¼‰
    scraped_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,  -- çˆ¬å–æ—¶é—´
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP   -- æ›´æ–°æ—¶é—´
);

-- ç´¢å¼•
CREATE INDEX idx_content_hash ON articles(content_hash);
CREATE INDEX idx_author ON articles(author);
CREATE INDEX idx_create_time ON articles(create_time);
```

### æ•°æ®åº“ API

`DatabaseManager` æä¾›ä»¥ä¸‹ä¸»è¦æ–¹æ³•ï¼š

```python
from utils.database import DatabaseManager

# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆæ¨èï¼‰
with DatabaseManager("database/binance_square.db") as db:
    # è·å–æ–‡ç« æ€»æ•°
    count = db.get_article_count()
    print(f"æ•°æ®åº“ä¸­å…±æœ‰ {count} ç¯‡æ–‡ç« ")

    # è·å–æœ€æ–°çš„ 10 ç¯‡æ–‡ç« 
    articles = db.get_all_articles(limit=10)

    # æ ¹æ®ä½œè€…æŸ¥è¯¢
    author_articles = db.get_articles_by_author("goingsun")

    # æ ¹æ®å“ˆå¸Œè·å–æ–‡ç« 
    article = db.get_article_by_hash(content_hash)

    # æ‰‹åŠ¨æ’å…¥æ–‡ç« 
    article = {
        "author": "goingsun",
        "card_title": "æ–‡ç« æ ‡é¢˜",
        "card_description": "æ–‡ç« å†…å®¹",
        "create-time": "2024-01-01 10:00:00",
        "imgs": ["url1.jpg", "url2.jpg"]
    }
    db.insert_article(article)

    # æ‰¹é‡æ’å…¥
    db.insert_articles_batch([article1, article2, ...])
```

### ä¸»è¦æ–¹æ³•åˆ—è¡¨

- `insert_article(article)` - æ’å…¥å•ç¯‡æ–‡ç« 
- `insert_articles_batch(articles)` - æ‰¹é‡æ’å…¥æ–‡ç« 
- `get_article_by_hash(hash)` - æ ¹æ®å“ˆå¸Œè·å–æ–‡ç« 
- `get_articles_by_author(author)` - è·å–æŒ‡å®šä½œè€…çš„æ‰€æœ‰æ–‡ç« 
- `get_all_articles(limit)` - è·å–æ‰€æœ‰æ–‡ç« 
- `get_article_count()` - è·å–æ–‡ç« æ€»æ•°
- `update_article(hash, updates)` - æ›´æ–°æ–‡ç« 
- `delete_article_by_hash(hash)` - åˆ é™¤æ–‡ç« 
- `generate_content_hash(article)` - ç”Ÿæˆæ–‡ç« å“ˆå¸Œå€¼

## ğŸ“‹ é…ç½®æ–‡ä»¶è¯´æ˜

å®Œæ•´çš„ `config.json` é…ç½®ç¤ºä¾‹ï¼š

```json
{
  "kol_username": "goingsun",                    // ç›®æ ‡ KOL ç”¨æˆ·å
  "scrape_method": "auto",                       // çˆ¬å–æ–¹æ³•ï¼ˆä¿ç•™å­—æ®µï¼‰

  "api_config": {                                // API é…ç½®ï¼ˆä¿ç•™å­—æ®µï¼‰
    "base_url": "https://www.binance.com",
    "profile_endpoint": "",
    "articles_endpoint": "",
    "headers": {
      "User-Agent": "Mozilla/5.0...",
      "Accept": "application/json, text/plain, */*",
      "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8"
    },
    "params": {
      "page": 1,
      "size": 20
    }
  },

  "drission_config": {                           // DrissionPage é…ç½®
    "headless": false,                           // æ˜¯å¦æ— å¤´æ¨¡å¼
    "scroll_times": 3,                           // æ»šåŠ¨æ¬¡æ•°ï¼ˆä¿ç•™å­—æ®µï¼‰
    "max_articles": 10,                          // æœ€å¤§æ–‡ç« æ•°ï¼ˆä¿ç•™å­—æ®µï¼‰
    "selectors": {                               // CSS é€‰æ‹©å™¨
      "title": "[class*=\"title\"]",
      "content": "[class*=\"content\"]",
      "time": "[class*=\"time\"]"
    }
  },

  "scheduler_config": {                          // è°ƒåº¦å™¨é…ç½®
    "enabled": true,                             // æ˜¯å¦å¯ç”¨å®šæ—¶ä»»åŠ¡
    "interval_hours": 1,                         // é—´éš”å°æ—¶æ•°
    "interval_minutes": 0,                       // é—´éš”åˆ†é’Ÿæ•°
    "headless": true,                            // æ˜¯å¦æ— å¤´æ¨¡å¼
    "run_immediately": false                     // å¯åŠ¨æ—¶æ˜¯å¦ç«‹å³æ‰§è¡Œ
  },

  "database": {                                  // æ•°æ®åº“é…ç½®
    "db_path": "database/binance_square.db"      // æ•°æ®åº“æ–‡ä»¶è·¯å¾„
  },

  "output": {                                    // è¾“å‡ºé…ç½®
    "save_to_file": true,                        // æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
    "file_format": "json",                       // æ–‡ä»¶æ ¼å¼
    "output_dir": "data"                         // è¾“å‡ºç›®å½•
  },

  "advanced": {                                  // é«˜çº§é…ç½®
    "request_delay": 1,                          // è¯·æ±‚å»¶è¿Ÿï¼ˆç§’ï¼‰
    "max_retries": 3,                            // æœ€å¤§é‡è¯•æ¬¡æ•°
    "timeout": 30,                               // è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    "enable_logging": true,                      // æ˜¯å¦å¯ç”¨æ—¥å¿—
    "log_level": "INFO"                          // æ—¥å¿—çº§åˆ«
  }
}
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **åˆæ³•åˆè§„**ï¼šç¡®ä¿ä½¿ç”¨ç¬¦åˆå¸å®‰æœåŠ¡æ¡æ¬¾ï¼Œä»…ç”¨äºå­¦ä¹ å’Œç ”ç©¶ç›®çš„
2. **é¢‘ç‡æ§åˆ¶**ï¼šå»ºè®®è®¾ç½®åˆç†çš„è¯·æ±‚é—´éš”ï¼Œé¿å…å¯¹æœåŠ¡å™¨é€ æˆè¿‡å¤§å‹åŠ›
3. **æ•°æ®ä¿æŠ¤**ï¼šä¸è¦åˆ†äº«ã€ä¼ æ’­æˆ–æ»¥ç”¨çˆ¬å–çš„æ•°æ®
4. **å¼‚å¸¸å¤„ç†**ï¼šåšå¥½é”™è¯¯é‡è¯•å’Œæ—¥å¿—è®°å½•ï¼ŒåŠæ—¶å‘ç°å’Œè§£å†³é—®é¢˜
5. **èµ„æºå ç”¨**ï¼šç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨æ— å¤´æ¨¡å¼ï¼ˆ`headless=True`ï¼‰ä»¥å‡å°‘èµ„æºå ç”¨

## â“ å¸¸è§é—®é¢˜

### Q1: DrissionPage æç¤ºæµè§ˆå™¨å¯åŠ¨å¤±è´¥ï¼Ÿ
A: ç¡®ä¿ç³»ç»Ÿå·²å®‰è£… Chrome æµè§ˆå™¨ï¼ŒDrissionPage ä¼šè‡ªåŠ¨å¯»æ‰¾ Chrome å¯æ‰§è¡Œæ–‡ä»¶ã€‚

### Q2: é‡åˆ° Cloudflare éªŒè¯ï¼Ÿ
A: é¡¹ç›®å·²é›†æˆ Cloudflare ç»•è¿‡é€»è¾‘ï¼Œå¦‚æœä»ç„¶å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ‰å¤´æ¨¡å¼ï¼ˆ`headless=False`ï¼‰ã€‚

### Q3: ä¸ºä»€ä¹ˆæœ‰äº›æ–‡ç« æ²¡æœ‰è¢«æŠ“å–åˆ°ï¼Ÿ
A: å¯èƒ½æ˜¯ç½®é¡¶æ–‡ç« ï¼ˆå·²è‡ªåŠ¨è·³è¿‡ï¼‰æˆ–è€…é¡µé¢åŠ è½½ä¸å®Œæ•´ï¼Œå¯ä»¥å°è¯•åˆ·æ–°åé‡æ–°è¿è¡Œã€‚

### Q4: å¦‚ä½•ä¿®æ”¹é‡å¤æ£€æµ‹çš„çµæ•åº¦ï¼Ÿ
A: åœ¨ `scrapers/binance_square.py` çš„ `extract_articles()` æ–¹æ³•ä¸­ä¿®æ”¹ `max_consecutive_duplicates` å‚æ•°ï¼ˆé»˜è®¤ä¸º 2ï¼‰ã€‚

### Q5: æ•°æ®åº“æ–‡ä»¶åœ¨å“ªé‡Œï¼Ÿ
A: é»˜è®¤ä½äº `database/binance_square.db`ï¼Œå¯åœ¨é…ç½®æ–‡ä»¶ä¸­ä¿®æ”¹è·¯å¾„ã€‚

### Q6: å¦‚ä½•åŒæ—¶çˆ¬å–å¤šä¸ª KOLï¼Ÿ
A: ä¸ºæ¯ä¸ª KOL åˆ›å»ºç‹¬ç«‹çš„çˆ¬è™«å®ä¾‹ï¼Œæˆ–ä½¿ç”¨å¾ªç¯ä¾æ¬¡çˆ¬å–ï¼š

```python
kol_list = ["goingsun", "username2", "username3"]

for kol in kol_list:
    scraper = BinanceSquareScraper(
        kol_username=kol,
        save_to_db=True
    )
    with scraper:
        articles = scraper.scrape()
        print(f"{kol}: è·å– {len(articles)} ç¯‡æ–°æ–‡ç« ")
```

## ğŸ”§ å¼€å‘è°ƒè¯•

### æŸ¥çœ‹æ—¥å¿—

æ—¥å¿—æ–‡ä»¶ä½äº `logs/` ç›®å½•ï¼š
- `binance_square_scraper.log` - çˆ¬è™«è¿è¡Œæ—¥å¿—
- `database.log` - æ•°æ®åº“æ“ä½œæ—¥å¿—
- `scheduler.log` - è°ƒåº¦å™¨æ—¥å¿—

### è°ƒè¯•æ¨¡å¼

è¿è¡Œçˆ¬è™«æ—¶ä½¿ç”¨æœ‰å¤´æ¨¡å¼å’Œè¯¦ç»†æ—¥å¿—ï¼š

```python
scraper = BinanceSquareScraper(
    kol_username="goingsun",
    headless=False,           # æ˜¾ç¤ºæµè§ˆå™¨çª—å£
    save_to_db=True
)
```

### æ•°æ®åº“æŸ¥è¯¢

æŸ¥çœ‹æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯ï¼š

```python
from utils.database import DatabaseManager

with DatabaseManager("database/binance_square.db") as db:
    print(f"æ€»æ–‡ç« æ•°: {db.get_article_count()}")

    # æŸ¥çœ‹æœ€æ–°çš„ 5 ç¯‡æ–‡ç« 
    articles = db.get_all_articles(limit=5)
    for article in articles:
        print(f"- {article['card_title']}")
```

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ï¼Œè¯·å‹¿ç”¨äºå•†ä¸šç”¨é€”ã€‚

## ğŸ™ è‡´è°¢

- [DrissionPage](https://github.com/g1879/DrissionPage) - å¼ºå¤§çš„æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·
- [APScheduler](https://github.com/agronholm/apscheduler) - Python å®šæ—¶ä»»åŠ¡è°ƒåº¦åº“
